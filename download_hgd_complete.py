#!/usr/bin/env python3
"""
å®Œæ•´ä¸‹è½½HGDæ•°æ®é›†çš„è„šæœ¬
"""

import os
import requests
from urllib.parse import urljoin
import time

def download_file(url, local_path, timeout=300):
    """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
    try:
        print(f"ä¸‹è½½: {url}")
        print(f"ä¿å­˜åˆ°: {local_path}")
        
        # åˆ›å»ºç›®å½•
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        
        # ä¸‹è½½æ–‡ä»¶
        response = requests.get(url, stream=True, timeout=timeout)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded = 0
        
        with open(local_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    if total_size > 0:
                        progress = (downloaded / total_size) * 100
                        print(f"\rè¿›åº¦: {progress:.1f}% ({downloaded}/{total_size})", end='')
        
        print(f"\nâœ“ ä¸‹è½½å®Œæˆ: {local_path}")
        return True
        
    except Exception as e:
        print(f"\nâœ— ä¸‹è½½å¤±è´¥: {e}")
        return False

def download_hgd_dataset():
    """ä¸‹è½½å®Œæ•´çš„HGDæ•°æ®é›†"""
    
    base_url = "https://gin.g-node.org/robintibor/high-gamma-dataset/raw/master/data/"
    
    # ç›®æ ‡è·¯å¾„
    target_base = "C:/Users/å¾å–„è‹¥/mne_data/MNE-schirrmeister2017-data/robintibor/high-gamma-dataset/raw/master/data/"
    
    print("=== å¼€å§‹ä¸‹è½½HGDæ•°æ®é›† ===")
    print(f"ç›®æ ‡è·¯å¾„: {target_base}")
    
    success_count = 0
    total_count = 0
    
    # ä¸‹è½½æ‰€æœ‰å—è¯•è€…çš„æ•°æ®
    for subject in range(1, 15):  # 14ä¸ªå—è¯•è€…
        for data_type in ['train', 'test']:
            
            # ä¸‹è½½.edfæ–‡ä»¶ï¼ˆä¸»è¦æ•°æ®æ–‡ä»¶ï¼‰
            edf_url = urljoin(base_url, f"{data_type}/{subject}.edf")
            edf_path = os.path.join(target_base, data_type, f"{subject}.edf")
            
            print(f"\n--- å—è¯•è€… {subject} ({data_type}) ---")
            
            total_count += 1
            if download_file(edf_url, edf_path):
                success_count += 1
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(edf_path)
                print(f"æ–‡ä»¶å¤§å°: {file_size / (1024*1024):.1f} MB")
                
                if file_size < 1024:  # å¦‚æœæ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æ˜¯é”™è¯¯
                    print("âš ï¸ è­¦å‘Š: æ–‡ä»¶å¤§å°å¼‚å¸¸å°ï¼Œå¯èƒ½ä¸‹è½½ä¸å®Œæ•´")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…æœåŠ¡å™¨é™åˆ¶
            time.sleep(1)
    
    print(f"\n=== ä¸‹è½½å®Œæˆ ===")
    print(f"æˆåŠŸ: {success_count}/{total_count}")
    
    if success_count == total_count:
        print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶ä¸‹è½½æˆåŠŸï¼")
        return True
    else:
        print(f"âš ï¸ æœ‰ {total_count - success_count} ä¸ªæ–‡ä»¶ä¸‹è½½å¤±è´¥")
        return False

def verify_hgd_data():
    """éªŒè¯ä¸‹è½½çš„HGDæ•°æ®"""
    
    target_base = "C:/Users/å¾å–„è‹¥/mne_data/MNE-schirrmeister2017-data/robintibor/high-gamma-dataset/raw/master/data/"
    
    print("\n=== éªŒè¯HGDæ•°æ® ===")
    
    train_files = []
    test_files = []
    
    for subject in range(1, 15):
        train_file = os.path.join(target_base, "train", f"{subject}.edf")
        test_file = os.path.join(target_base, "test", f"{subject}.edf")
        
        if os.path.exists(train_file):
            size = os.path.getsize(train_file) / (1024*1024)
            train_files.append((subject, size))
            
        if os.path.exists(test_file):
            size = os.path.getsize(test_file) / (1024*1024)
            test_files.append((subject, size))
    
    print(f"è®­ç»ƒæ–‡ä»¶: {len(train_files)}/14")
    print(f"æµ‹è¯•æ–‡ä»¶: {len(test_files)}/14")
    
    if train_files:
        print("è®­ç»ƒæ–‡ä»¶å¤§å°:")
        for subject, size in train_files[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            print(f"  å—è¯•è€… {subject}: {size:.1f} MB")
    
    if test_files:
        print("æµ‹è¯•æ–‡ä»¶å¤§å°:")
        for subject, size in test_files[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            print(f"  å—è¯•è€… {subject}: {size:.1f} MB")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œè®­ç»ƒ
    if len(train_files) >= 5 and len(test_files) >= 5:
        print("âœ“ æœ‰è¶³å¤Ÿçš„æ•°æ®å¯ä»¥å¼€å§‹è®­ç»ƒ")
        return True
    else:
        print("âœ— æ•°æ®ä¸è¶³ï¼Œéœ€è¦æ›´å¤šä¸‹è½½")
        return False

if __name__ == "__main__":
    print("å¼€å§‹HGDæ•°æ®é›†å®Œæ•´ä¸‹è½½...")
    
    # ä¸‹è½½æ•°æ®
    download_success = download_hgd_dataset()
    
    # éªŒè¯æ•°æ®
    verify_success = verify_hgd_data()
    
    if download_success and verify_success:
        print("\nğŸ‰ HGDæ•°æ®é›†å‡†å¤‡å®Œæˆï¼å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚")
    else:
        print("\nâŒ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ‰‹åŠ¨ä¸‹è½½æ•°æ®")
        print("å¤‡ç”¨ä¸‹è½½åœ°å€:")
        print("- https://gin.g-node.org/robintibor/high-gamma-dataset")
        print("- https://github.com/robintibor/high-gamma-dataset")
