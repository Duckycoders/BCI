#!/usr/bin/env python3
"""
ç›´æ¥ä¸‹è½½HGDæ•°æ®é›†çš„.edfæ–‡ä»¶
"""

import os
import requests
import time
from urllib.parse import urljoin

def download_large_file(url, local_path, chunk_size=8192):
    """ä¸‹è½½å¤§æ–‡ä»¶ï¼Œæ˜¾ç¤ºè¿›åº¦"""
    try:
        print(f"å¼€å§‹ä¸‹è½½: {os.path.basename(local_path)}")
        
        # åˆ›å»ºç›®å½•
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”å¤§å°åˆç†
        if os.path.exists(local_path):
            size = os.path.getsize(local_path)
            if size > 100 * 1024 * 1024:  # å¤§äº100MB
                print(f"âœ“ æ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°æ­£å¸¸: {size / (1024*1024):.1f} MB")
                return True
            else:
                print(f"âš ï¸ ç°æœ‰æ–‡ä»¶å¤ªå°({size}å­—èŠ‚)ï¼Œé‡æ–°ä¸‹è½½...")
                os.remove(local_path)
        
        # ä¸‹è½½æ–‡ä»¶
        with requests.get(url, stream=True, timeout=30) as response:
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            
            start_time = time.time()
            
            with open(local_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        
                        # æ˜¾ç¤ºè¿›åº¦
                        if total_size > 0:
                            progress = (downloaded / total_size) * 100
                            elapsed = time.time() - start_time
                            speed = downloaded / (1024 * 1024) / elapsed if elapsed > 0 else 0
                            print(f"\r  è¿›åº¦: {progress:.1f}% ({downloaded/(1024*1024):.1f}/{total_size/(1024*1024):.1f} MB) é€Ÿåº¦: {speed:.1f} MB/s", end='')
        
        print(f"\nâœ“ ä¸‹è½½å®Œæˆ!")
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        final_size = os.path.getsize(local_path)
        if final_size > 100 * 1024 * 1024:
            print(f"âœ“ æ–‡ä»¶å¤§å°éªŒè¯é€šè¿‡: {final_size / (1024*1024):.1f} MB")
            return True
        else:
            print(f"âœ— æ–‡ä»¶å¤§å°å¼‚å¸¸: {final_size} å­—èŠ‚")
            return False
            
    except Exception as e:
        print(f"\nâœ— ä¸‹è½½å¤±è´¥: {e}")
        return False

def download_essential_hgd_data():
    """ä¸‹è½½å¿…è¦çš„HGDæ•°æ®ï¼ˆå‰å‡ ä¸ªå—è¯•è€…ï¼‰"""
    
    base_url = "https://gin.g-node.org/robintibor/high-gamma-dataset/raw/master/data/"
    target_base = "C:/Users/å¾å–„è‹¥/mne_data/high-gamma-dataset/data/"
    
    print("=== ä¸‹è½½å¿…è¦çš„HGDæ•°æ® ===")
    print("å…ˆä¸‹è½½å‰3ä¸ªå—è¯•è€…çš„æ•°æ®ç”¨äºæµ‹è¯•...")
    
    success_count = 0
    
    # åªä¸‹è½½å‰3ä¸ªå—è¯•è€…çš„æ•°æ®
    for subject in range(1, 4):  # å—è¯•è€…1-3
        for data_type in ['train', 'test']:
            
            edf_url = urljoin(base_url, f"{data_type}/{subject}.edf")
            edf_path = os.path.join(target_base, data_type, f"{subject}.edf")
            
            print(f"\n--- å—è¯•è€… {subject} ({data_type}) ---")
            
            if download_large_file(edf_url, edf_path):
                success_count += 1
            
            # çŸ­æš‚æš‚åœé¿å…æœåŠ¡å™¨é™åˆ¶
            time.sleep(2)
    
    print(f"\n=== ä¸‹è½½å®Œæˆ ===")
    print(f"æˆåŠŸä¸‹è½½: {success_count}/6 ä¸ªæ–‡ä»¶")
    
    if success_count >= 4:  # è‡³å°‘æœ‰2ä¸ªå—è¯•è€…çš„å®Œæ•´æ•°æ®
        print("âœ“ æœ‰è¶³å¤Ÿçš„æ•°æ®å¯ä»¥å¼€å§‹æµ‹è¯•è®­ç»ƒ")
        return True
    else:
        print("âœ— ä¸‹è½½çš„æ•°æ®ä¸è¶³")
        return False

def test_hgd_loading():
    """æµ‹è¯•HGDæ•°æ®åŠ è½½"""
    try:
        from preprocess_HGD import load_HGD_data_moabb
        
        data_path = "C:/Users/å¾å–„è‹¥/mne_data/high-gamma-dataset/data/"
        
        print(f"\n=== æµ‹è¯•HGDæ•°æ®åŠ è½½ ===")
        
        # æµ‹è¯•ç¬¬ä¸€ä¸ªå—è¯•è€…
        X_train, y_train = load_HGD_data_moabb(data_path, 1, True)
        X_test, y_test = load_HGD_data_moabb(data_path, 1, False)
        
        print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"è®­ç»ƒæ•°æ®: {X_train.shape}")
        print(f"æµ‹è¯•æ•°æ®: {X_test.shape}")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("å¼€å§‹HGDæ•°æ®é›†ä¸‹è½½...")
    
    # ä¸‹è½½å¿…è¦æ•°æ®
    download_success = download_essential_hgd_data()
    
    if download_success:
        # æµ‹è¯•åŠ è½½
        load_success = test_hgd_loading()
        
        if load_success:
            print("\nğŸ‰ HGDæ•°æ®é›†è®¾ç½®å®Œæˆï¼å¯ä»¥å¼€å§‹è®­ç»ƒã€‚")
        else:
            print("\nâš ï¸ æ•°æ®ä¸‹è½½æˆåŠŸä½†åŠ è½½æœ‰é—®é¢˜ï¼Œå¯èƒ½éœ€è¦è°ƒè¯•")
    else:
        print("\nâŒ æ•°æ®ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
